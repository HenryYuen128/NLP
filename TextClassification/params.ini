[pretrained_models]
pretrain_model = {'macbert_base': '/expand/Henry/model_zoo/chinese-macbert-base',
                  'macbert_large': 'hfl/chinese-macbert-large',
                  'roberta_large': '/expand/Henry/model_zoo/chinese-roberta-wwm-ext-large',
                  'albert_base': '/expand/Henry/model_zoo/albert-base-chinese-cluecorpussmall',
                  'mengzi_base': 'Langboat/mengzi-bert-base',
                  'roberta_base': '/expand/Henry/model_zoo/chinese-roberta-wwm-ext',
                  'con': '/data/henry.yuan/code/PyTorchLearning/kol_cls/mengzi_contrastive_model',
                  'lbert': 'hfl/chinese-lert-base',
                  'lbert_con':'/data/henry.yuan/code/PyTorchLearning/kol_cls/lbert_contrastive_model',
                  'electra': '/expand/Henry/model_zoo/electra-hongkongese-base-discriminator/',
                  'con_roberta': '/expand/Henry/code/AIA_NLP/iSay-NPS/contrastive_learning/output/aia_model/135',
                  'multilingual_roberta': 'xlm-roberta-base',
                  'xlm_roberta_base': '/expand/Henry/model_zoo/xlm-roberta-base',
                  'albert_en': '/expand/Henry/model_zoo/albert-base-v2',
                  'bert_multilingual': '/expand/Henry/model_zoo/bert-base-multilingual-cased',
                  'tiny_bert': '/expand/Henry/model_zoo/TinyBERT_General_4L_312D',
                  'deberta_97M':'/expand/Henry/model_zoo/Erlangshen-DeBERTa-v2-97M-Chinese',
                  'electra_base': '/expand/Henry/model_zoo/chinese-electra-180g-base-discriminator',
                  'electra_large': '/expand/Henry/model_zoo/chinese-electra-180g-large-discriminator',
                  'deberta_320M': '/expand/Henry/model_zoo/Erlangshen-DeBERTa-v2-320M-Chinese'
                  }

[model_conf]
plm_name = hfl/chinese-roberta-wwm-ext
model_type = bert
max_length = 128


[train_conf]
task_name=hotel_sentiment
train_set_path=/home/henry/code/NLP/data/ChnSentiCorp_htl_all.csv
dev_set_path=/home/henry/code/NLP/data/ChnSentiCorp_htl_all.csv
test_set_path=/home/henry/code/NLP/data/ChnSentiCorp_htl_all.csv
label_col = label
label_list = Positive|Negative
problem_type = single_label_classification

text_col = review
gradient_checkpointing = True
batch_size = 128
lr = 4e-5
early_stopping_patience=3
epoch_num=100
cls_threshold = 0.5
hidden_dropout_prob = 0.1
WeightedBCELoss = False
FocalLoss = False

# mean_cat_cls, weighted_hidden, mean, last3avg, else=cls 
pooling = mean

# addition vocab
add_token=False
vocab_path=/expand/Henry/code/AIA_NLP/iSay-NPS/custom_hight_freq_vocab.list


# cate feat
is_cate_feat = True
cate_feat_col = sub_stage
cate_feat_names = CSAT_BUY_REASON_|CSAT_CLAIM_REASON_|NPS_AGENT_REASON|CSAT_ONBOARDING_REASON|CSAT_GET_SUPPORT_REASON
cate_feat_hidden_size = 128

[output_config]
pred_output_col_name = level2
test_with_label = True


[ptuning_config]
prefix_projection = mlp
pre_seq_len = 7
strategy = NO
freeze_bert = False